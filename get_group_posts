#!/bin/bash -ex

ACCESS_TOKEN="$1"
GROUP_ID="$2"
MESSAGE_LIMIT="$3"
OUT_FILE="$4"
NEXT_PAGE="null"
PWD=`pwd`
TEMP_FILE=${PWD}/tmp.json
PARSED_FILE="${PWD}/parsed.json"
LINKS_FILE="${PWD}/links.txt"
URL= "https://graph.facebook.com/v7.0/${GROUP_ID}/feed?fields=attachments%7Bunshimmed_url%7D%2Cmessage&limit=${MESSAGE_LIMIT}&access_token=${ACCESS_TOKEN}"


function parse_file_for_links() {
 cat ${TEMP_FILE} | jq -r '.data[] | select(.attachments != null) | {message: .message, link: .attachments.data[].unshimmed_url}' >> ${PARSED_FILE}
}

# Be cautious, developer API has a rate limit per hour... I've found doing this 5-10 times will hit the limit
function get_posts() {
    curl --write-out -i -X GET $URL -o $TEMP_FILE
    cat ${TEMP_FILE} | tee -a data.txt # This will be a temporary place for data to go so I can develop on other things without hitting rate limit
    URL=`cat ${TEMP_FILE} | jq -r '.paging.next'`
    parse_file_for_links
}

get_posts
while ! [[ "$URL" == "null" ]]; do
    get_posts
done

# at this point, we should have a list of all songs
jq -s '.' < ${PARSED_FILE} > ${OUT_FILE}
rm ${TEMP_FILE}
rm ${PARSED_FILE}

cat ${OUT_FILE} | jq -r '.[] | .link' > ${LINKS_FILE}
